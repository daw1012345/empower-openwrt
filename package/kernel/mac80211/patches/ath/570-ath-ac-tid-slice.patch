--- a/drivers/net/wireless/ath/ath9k/ath9k.h
+++ b/drivers/net/wireless/ath/ath9k/ath9k.h
@@ -102,6 +102,9 @@ int ath_descdma_setup(struct ath_softc *
 	 (((_tid) == 4) || ((_tid) == 5)) ? IEEE80211_AC_VI :	\
 	 IEEE80211_AC_VO)
 
+#define ATH_NUM_DATA_TX_QUEUES 4
+#define ATH_EMPOWER_DEFAULT_QUEUE 6
+
 #define ATH_AGGR_DELIM_SZ          4
 #define ATH_AGGR_MINPLEN           256 /* in bytes, minimum packet length */
 /* number of delimiters for encryption padding */
@@ -173,6 +176,8 @@ struct ath_txq {
 	u8 txq_tailidx;
 	int pending_frames;
 	struct sk_buff_head complete_q;
+
+	int current_slice; // Uninit if == -1
 };
 
 struct ath_frame_info {
@@ -265,7 +270,7 @@ struct ath_node {
 
 	bool sleeping;
 	bool no_ps_filter;
-	s64 airtime_deficit[IEEE80211_NUM_ACS];
+	s64 airtime_deficit[EMPOWER_NUM_SLICE];
 	u32 airtime_rx_start;
 
 #ifdef CPTCFG_ATH9K_STATION_STATISTICS
@@ -286,6 +291,13 @@ struct ath_tx_control {
 };
 
 
+struct ath_empower_slice {
+	u8 slice;
+
+	spinlock_t slice_cfg_lock;
+	struct ath9k_tx_queue_info slice_config;
+};
+
 /**
  * @txq_map:  Index is mac80211 queue number.  This is
  *  not necessarily the same as the hardware queue number
@@ -299,7 +311,16 @@ struct ath_tx {
 	struct ath_descdma txdma;
 	struct ath_txq *txq_map[IEEE80211_NUM_ACS];
 	struct ath_txq *uapsdq;
-	u16 max_aggr_framelen[IEEE80211_NUM_ACS][4][32];
+	u16 max_aggr_framelen[EMPOWER_NUM_SLICE][4][32];
+
+	struct ath_empower_slice slices[EMPOWER_NUM_SLICE];
+	
+	spinlock_t queue_lock;
+	struct sk_buff_head queue;
+
+	// The following needs no locking due to serialized access
+	u64 handled_slices;
+	u16 inactive_queues;
 };
 
 struct ath_rx_edma {
@@ -336,7 +357,7 @@ struct ath_acq {
 struct ath_chanctx {
 	struct cfg80211_chan_def chandef;
 	struct list_head vifs;
-	struct ath_acq acq[IEEE80211_NUM_ACS];
+	struct ath_acq acq;
 	int hw_queue_base;
 
 	/* do not dereference, use for comparison only */
@@ -440,10 +461,7 @@ ath_node_to_tid(struct ath_node *an, u8
 	struct ieee80211_txq *txq;
 
 	BUG_ON(!vif);
-	if (sta)
-		txq = sta->txq[tidno % ARRAY_SIZE(sta->txq)];
-	else
-		txq = vif->txq;
+	txq = sta->txq[tidno];
 
 	return (struct ath_atx_tid *) txq->drv_priv;
 }
@@ -458,7 +476,7 @@ ath_node_to_tid(struct ath_node *an, u8
 void ath_chanctx_init(struct ath_softc *sc);
 void ath_chanctx_set_channel(struct ath_softc *sc, struct ath_chanctx *ctx,
 			     struct cfg80211_chan_def *chandef);
-
+int ath9k_configure_queue_for_slice(struct ath_softc *sc, u16 slice, struct ath_txq *txq);
 #ifdef CPTCFG_ATH9K_CHANNEL_CONTEXT
 
 static inline struct ath_chanctx *
@@ -593,7 +611,7 @@ bool ath_drain_all_txq(struct ath_softc
 void ath_draintxq(struct ath_softc *sc, struct ath_txq *txq);
 void ath_tx_node_init(struct ath_softc *sc, struct ath_node *an);
 void ath_tx_node_cleanup(struct ath_softc *sc, struct ath_node *an);
-void ath_txq_schedule(struct ath_softc *sc, struct ath_txq *txq);
+bool ath_txq_schedule(struct ath_softc *sc, struct ath_txq *txq);
 void ath_txq_schedule_all(struct ath_softc *sc);
 int ath_tx_init(struct ath_softc *sc, int nbufs);
 int ath_txq_update(struct ath_softc *sc, int qnum,
@@ -684,6 +702,8 @@ void ath9k_calculate_iter_data(struct at
 void ath9k_calculate_summary_state(struct ath_softc *sc,
 				   struct ath_chanctx *ctx);
 void ath9k_set_txpower(struct ath_softc *sc, struct ieee80211_vif *vif);
+bool ath9k_has_pending_frames(struct ath_softc *sc, struct ath_txq *txq,
+				     bool sw_pending);
 
 /*******************/
 /* Beacon Handling */
--- a/drivers/net/wireless/ath/ath9k/debug.c
+++ b/drivers/net/wireless/ath/ath9k/debug.c
@@ -639,13 +639,10 @@ static int read_file_queues(struct seq_f
 	struct ath_softc *sc = hw->priv;
 	struct ath_txq *txq;
 	int i;
-	static const char *qname[4] = {
-		"VO", "VI", "BE", "BK"
-	};
 
-	for (i = 0; i < IEEE80211_NUM_ACS; i++) {
-		txq = sc->tx.txq_map[i];
-		seq_printf(file, "(%s):  ", qname[i]);
+	for (i = 0; i < ATH_NUM_DATA_TX_QUEUES; i++) {
+		txq = &sc->tx.txq[i];
+		seq_printf(file, "(%u):  ", i);
 		print_queue(sc, txq, file);
 	}
 
--- a/drivers/net/wireless/ath/ath9k/debug_sta.c
+++ b/drivers/net/wireless/ath/ath9k/debug_sta.c
@@ -52,10 +52,8 @@ static ssize_t read_file_node_aggr(struc
 			 "TID", "SEQ_START", "SEQ_NEXT", "BAW_SIZE",
 			 "BAW_HEAD", "BAW_TAIL", "BAR_IDX", "SCHED", "PAUSED");
 
-	for (tidno = 0; tidno < IEEE80211_NUM_TIDS; tidno++) {
+	for (tidno = 0; tidno < EMPOWER_NUM_SLICE; tidno++) {
 		tid = ath_node_to_tid(an, tidno);
-		txq = tid->txq;
-		ath_txq_lock(sc, txq);
 		if (tid->active) {
 			len += scnprintf(buf + len, size - len,
 					 "%3d%11d%10d%10d%10d%10d%9d%6d\n",
@@ -68,7 +66,6 @@ static ssize_t read_file_node_aggr(struc
 					 tid->bar_index,
 					 !list_empty(&tid->list));
 		}
-		ath_txq_unlock(sc, txq);
 	}
 exit:
 	retval = simple_read_from_buffer(user_buf, count, ppos, buf, len);
--- a/drivers/net/wireless/ath/ath9k/htc.h
+++ b/drivers/net/wireless/ath/ath9k/htc.h
@@ -345,7 +345,7 @@ struct ath_tx_stats {
 	u32 skb_success_bytes;
 	u32 skb_failed;
 	u32 cab_queued;
-	u32 queue_stats[IEEE80211_NUM_ACS];
+	u32 queue_stats[ATH_NUM_DATA_TX_QUEUES];
 };
 
 struct ath_skbrx_stats {
--- a/drivers/net/wireless/ath/ath9k/init.c
+++ b/drivers/net/wireless/ath/ath9k/init.c
@@ -407,16 +407,24 @@ static int ath9k_init_queues(struct ath_
 {
 	int i = 0;
 
-	sc->beacon.beaconq = ath9k_hw_beaconq_setup(sc->sc_ah);
-	sc->beacon.cabq = ath_txq_setup(sc, ATH9K_TX_QUEUE_CAB, 0);
-	ath_cabq_update(sc);
+	// sc->beacon.beaconq = ath9k_hw_beaconq_setup(sc->sc_ah);
+	// sc->beacon.cabq = ath_txq_setup(sc, ATH9K_TX_QUEUE_CAB, 0);
+	// ath_cabq_update(sc);
 
-	sc->tx.uapsdq = ath_txq_setup(sc, ATH9K_TX_QUEUE_UAPSD, 0);
+	// sc->tx.uapsdq = ath_txq_setup(sc, ATH9K_TX_QUEUE_UAPSD, 0);
 
+	for (i = 0; i < ATH_NUM_DATA_TX_QUEUES; i++) {
+		// We don't use txq_map anymore, just force the qnum to 0
+		struct ath_txq *q = ath_txq_setup(sc, ATH9K_TX_QUEUE_DATA, i);
+		q->mac80211_qnum = 0;
+		q->current_slice = -1;
+	}
+
+	// Forward everything we don't know about to a default TXq (shared with PS-Poll which is disabled)
 	for (i = 0; i < IEEE80211_NUM_ACS; i++) {
-		sc->tx.txq_map[i] = ath_txq_setup(sc, ATH9K_TX_QUEUE_DATA, i);
-		sc->tx.txq_map[i]->mac80211_qnum = i;
+		sc->tx.txq_map[i] = &sc->tx.txq[ATH_EMPOWER_DEFAULT_QUEUE];
 	}
+
 	return 0;
 }
 
@@ -682,8 +690,7 @@ static int ath9k_init_softc(u16 devid, s
 
 	/* Will be cleared in ath9k_start() */
 	set_bit(ATH_OP_INVALID, &common->op_flags);
-	sc->airtime_flags = (AIRTIME_USE_TX | AIRTIME_USE_RX |
-			     AIRTIME_USE_NEW_QUEUES);
+	sc->airtime_flags = 0;
 
 	sc->sc_ah = ah;
 	sc->dfs_detector = dfs_pattern_detector_init(common, NL80211_DFS_UNSET);
@@ -730,16 +737,33 @@ static int ath9k_init_softc(u16 devid, s
 	    (pCap->hw_caps & ATH9K_HW_CAP_BT_ANT_DIV))
 		common->bt_ant_diversity = 1;
 
+	for (i = 0; i < EMPOWER_NUM_SLICE; i++) {
+		sc->tx.slices[i].slice = i;
+		spin_lock_init(&sc->tx.slices[i].slice_cfg_lock);
+		sc->tx.slices[i].slice_config.tqi_subtype = i;
+		sc->tx.slices[i].slice_config.tqi_aifs = ATH9K_TXQ_USEDEFAULT;
+		sc->tx.slices[i].slice_config.tqi_cwmin = ATH9K_TXQ_USEDEFAULT;
+		sc->tx.slices[i].slice_config.tqi_cwmax = ATH9K_TXQ_USEDEFAULT;
+		sc->tx.slices[i].slice_config.tqi_physCompBuf = 0;
+		sc->tx.slices[i].slice_config.tqi_burstTime = 0;
+	}
+
+	sc->tx.handled_slices = 0;
+	sc->tx.inactive_queues = ((u16)1 << ATH_NUM_DATA_TX_QUEUES) - 1;
+
 	spin_lock_init(&common->cc_lock);
 	spin_lock_init(&sc->intr_lock);
 	spin_lock_init(&sc->sc_serial_rw);
 	spin_lock_init(&sc->sc_pm_lock);
 	spin_lock_init(&sc->chan_lock);
+	spin_lock_init(&sc->tx.queue_lock);
+	__skb_queue_head_init(&sc->tx.queue);
 	mutex_init(&sc->mutex);
 	tasklet_init(&sc->intr_tq, ath9k_tasklet, (unsigned long)sc);
 	tasklet_init(&sc->bcon_tasklet, ath9k_beacon_tasklet,
 		     (unsigned long)sc);
 
+
 	timer_setup(&sc->sleep_timer, ath_ps_full_sleep, 0);
 	INIT_WORK(&sc->hw_reset_work, ath_reset_work);
 	INIT_WORK(&sc->paprd_work, ath_paprd_calibrate);
@@ -938,16 +962,16 @@ static void ath9k_set_hw_capab(struct at
 	ieee80211_hw_set(hw, SUPPORT_FAST_XMIT);
 	ieee80211_hw_set(hw, SUPPORTS_CLONED_SKBS);
 
-	if (ath9k_ps_enable)
-		ieee80211_hw_set(hw, SUPPORTS_PS);
+	// if (ath9k_ps_enable)
+	// 	ieee80211_hw_set(hw, SUPPORTS_PS);
 
-	if (sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_HT) {
-		ieee80211_hw_set(hw, AMPDU_AGGREGATION);
+	// if (sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_HT) {
+	// 	ieee80211_hw_set(hw, AMPDU_AGGREGATION);
 
-		if (AR_SREV_9280_20_OR_LATER(ah))
-			hw->radiotap_mcs_details |=
-				IEEE80211_RADIOTAP_MCS_HAVE_STBC;
-	}
+	// 	if (AR_SREV_9280_20_OR_LATER(ah))
+	// 		hw->radiotap_mcs_details |=
+	// 			IEEE80211_RADIOTAP_MCS_HAVE_STBC;
+	// }
 
 	if (AR_SREV_9160_10_OR_LATER(sc->sc_ah) || ath9k_modparam_nohwcrypt)
 		ieee80211_hw_set(hw, MFP_CAPABLE);
--- a/drivers/net/wireless/ath/ath9k/link.c
+++ b/drivers/net/wireless/ath/ath9k/link.c
@@ -28,8 +28,8 @@ static bool ath_tx_complete_check(struct
 	if (sc->tx99_state)
 		return true;
 
-	for (i = 0; i < IEEE80211_NUM_ACS; i++) {
-		txq = sc->tx.txq_map[i];
+	for (i = 0; i < ATH_NUM_DATA_TX_QUEUES; i++) {
+		txq = &sc->tx.txq[i];
 
 		ath_txq_lock(sc, txq);
 		if (txq->axq_depth) {
@@ -48,6 +48,7 @@ static bool ath_tx_complete_check(struct
 reset:
 	ath_dbg(ath9k_hw_common(sc->sc_ah), RESET,
 		"tx hung, resetting the chip\n");
+	printk(KERN_ERR "TX hung!");
 	ath9k_queue_reset(sc, RESET_TYPE_TX_HANG);
 	return false;
 
@@ -83,6 +84,7 @@ bool ath_hw_check(struct ath_softc *sc)
 		ath_dbg(common, RESET,
 			"HW hang detected, schedule chip reset\n");
 		type = RESET_TYPE_MAC_HANG;
+		printk(KERN_ERR "HW Hang detected!");
 		ath9k_queue_reset(sc, type);
 	}
 
--- a/drivers/net/wireless/ath/ath9k/mac.c
+++ b/drivers/net/wireless/ath/ath9k/mac.c
@@ -245,14 +245,14 @@ bool ath9k_hw_set_txq_props(struct ath_h
 	qi->tqi_burstTime = qinfo->tqi_burstTime;
 	qi->tqi_readyTime = qinfo->tqi_readyTime;
 
-	switch (qinfo->tqi_subtype) {
-	case ATH9K_WME_UPSD:
-		if (qi->tqi_type == ATH9K_TX_QUEUE_DATA)
-			qi->tqi_intFlags = ATH9K_TXQ_USE_LOCKOUT_BKOFF_DIS;
-		break;
-	default:
-		break;
-	}
+	// switch (qinfo->tqi_subtype) {
+	// case ATH9K_WME_UPSD:
+	// 	if (qi->tqi_type == ATH9K_TX_QUEUE_DATA)
+	// 		qi->tqi_intFlags = ATH9K_TXQ_USE_LOCKOUT_BKOFF_DIS;
+	// 	break;
+	// default:
+	// 	break;
+	// }
 
 	return true;
 }
@@ -304,12 +304,12 @@ int ath9k_hw_setuptxqueue(struct ath_hw
 	case ATH9K_TX_QUEUE_CAB:
 		q = ATH9K_NUM_TX_QUEUES - 2;
 		break;
-	case ATH9K_TX_QUEUE_PSPOLL:
-		q = 1;
-		break;
 	case ATH9K_TX_QUEUE_UAPSD:
 		q = ATH9K_NUM_TX_QUEUES - 3;
 		break;
+	case ATH9K_TX_QUEUE_PSPOLL:
+		q = ATH9K_NUM_TX_QUEUES - 4;
+		break;
 	case ATH9K_TX_QUEUE_DATA:
 		q = qinfo->tqi_subtype;
 		break;
--- a/drivers/net/wireless/ath/ath9k/main.c
+++ b/drivers/net/wireless/ath/ath9k/main.c
@@ -56,7 +56,7 @@ u8 ath9k_parse_mpdudensity(u8 mpdudensit
 	}
 }
 
-static bool ath9k_has_pending_frames(struct ath_softc *sc, struct ath_txq *txq,
+bool ath9k_has_pending_frames(struct ath_softc *sc, struct ath_txq *txq,
 				     bool sw_pending)
 {
 	bool pending = false;
@@ -74,7 +74,7 @@ static bool ath9k_has_pending_frames(str
 	if (txq->mac80211_qnum >= 0) {
 		struct ath_acq *acq;
 
-		acq = &sc->cur_chan->acq[txq->mac80211_qnum];
+		acq = &sc->cur_chan->acq;
 		if (!list_empty(&acq->acq_new) || !list_empty(&acq->acq_old))
 			pending = true;
 	}
@@ -267,6 +267,7 @@ static bool ath_complete_reset(struct at
 			ath9k_set_beacon(sc);
 		}
 	work:
+		printk(KERN_ERR "Complete reset\n");
 		ath_restart_work(sc);
 		ath_txq_schedule_all(sc);
 	}
@@ -379,6 +380,8 @@ void ath9k_tasklet(unsigned long data)
 	unsigned long flags;
 	u32 status;
 	u32 rxmask;
+	int i;
+	bool empty, ret;
 
 	spin_lock_irqsave(&sc->intr_lock, flags);
 	status = sc->intrstatus;
@@ -390,6 +393,7 @@ void ath9k_tasklet(unsigned long data)
 
 	if (status & ATH9K_INT_FATAL) {
 		type = RESET_TYPE_FATAL_INT;
+		printk(KERN_ERR "Fatal error reported by chip in IRQ!\n");
 		ath9k_queue_reset(sc, type);
 		ath_dbg(common, RESET, "FATAL: Skipping interrupts\n");
 		goto out;
@@ -404,6 +408,7 @@ void ath9k_tasklet(unsigned long data)
 
 		if (ar9003_hw_bb_watchdog_check(ah)) {
 			type = RESET_TYPE_BB_WATCHDOG;
+			printk(KERN_ERR "Watchdog detected hang\n");
 			ath9k_queue_reset(sc, type);
 
 			ath_dbg(common, RESET,
@@ -416,6 +421,7 @@ void ath9k_tasklet(unsigned long data)
 		sc->gtt_cnt++;
 
 		if ((sc->gtt_cnt >= MAX_GTT_CNT) && !ath9k_hw_check_alive(ah)) {
+			printk(KERN_ERR "GTT Exceeded max!");
 			type = RESET_TYPE_TX_GTT;
 			ath9k_queue_reset(sc, type);
 			ath_dbg(common, RESET,
@@ -450,6 +456,8 @@ void ath9k_tasklet(unsigned long data)
 		ath_rx_tasklet(sc, 0, false);
 	}
 
+	// In here, we process a successful TX
+
 	if (status & ATH9K_INT_TX) {
 		if (ah->caps.hw_caps & ATH9K_HW_CAP_EDMA) {
 			/*
@@ -459,8 +467,9 @@ void ath9k_tasklet(unsigned long data)
 			 * gets reset to zero here.
 			 */
 			sc->gtt_cnt = 0;
+			printk(KERN_ERR "edma tasklet would have executed!");
 
-			ath_tx_edma_tasklet(sc);
+			// ath_tx_edma_tasklet(sc);
 		} else {
 			ath_tx_tasklet(sc);
 		}
@@ -468,6 +477,20 @@ void ath9k_tasklet(unsigned long data)
 		wake_up(&sc->tx_wait);
 	}
 
+	// Losing the lock here is fine because we are serialized and other threads only add to the queue
+	spin_lock_bh(&sc->tx.queue_lock);
+	empty = skb_queue_empty_lockless(&sc->tx.queue);
+	spin_unlock_bh(&sc->tx.queue_lock);
+
+	if (!empty) {
+		for (i = 0; i < ATH_NUM_DATA_TX_QUEUES; i++) {
+			ath_txq_lock(sc, &sc->tx.txq[i]);
+			ath_txq_schedule(sc, &sc->tx.txq[i]);
+			ath_txq_unlock(sc, &sc->tx.txq[i]);
+		}
+	}	// If we have data in the queue
+
+
 	if (status & ATH9K_INT_GENTIMER)
 		ath_gen_timer_isr(sc->sc_ah);
 
@@ -561,8 +584,10 @@ irqreturn_t ath_isr(int irq, void *dev)
 	    (status & ATH9K_INT_BB_WATCHDOG))
 		goto chip_reset;
 
-	if (status & ATH9K_INT_SWBA)
-		tasklet_schedule(&sc->bcon_tasklet);
+	if (status & ATH9K_INT_SWBA) {
+		printk(KERN_ERR "BCON requested but ignored");
+// tasklet_schedule(&sc->bcon_tasklet);
+	}
 
 	if (status & ATH9K_INT_TXURN)
 		ath9k_hw_updatetxtriglevel(ah, true);
@@ -720,6 +745,7 @@ static int ath9k_start(struct ieee80211_
 	clear_bit(ATH_OP_INVALID, &common->op_flags);
 	sc->sc_ah->is_monitoring = false;
 
+	printk(KERN_ERR "ATH9K START!!");
 	if (!ath_complete_reset(sc, false))
 		ah->reset_power_on = false;
 
@@ -761,8 +787,55 @@ static void ath9k_tx(struct ieee80211_hw
 	struct ath_softc *sc = hw->priv;
 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
 	struct ath_tx_control txctl;
+	struct ath_txq *txq;
 	struct ieee80211_hdr *hdr = (struct ieee80211_hdr *) skb->data;
 	unsigned long flags;
+	int slice, hw_q, i;
+	bool sent = false;
+	slice = skb->priority;
+	
+	if (slice >= EMPOWER_NUM_SLICE) {
+		printk(KERN_ERR "FAIL: Trying to send an SKB with priority of [%u] which exceeds expectations!\n", skb->priority);
+		goto exit;
+	}
+
+	for (i = 0; i < ATH_NUM_DATA_TX_QUEUES; i++) {
+		txq = &sc->tx.txq[i];
+		ath_txq_lock(sc, txq);
+		if (txq->current_slice == slice) {
+			struct ath_tx_control txctl = {
+				.txq = txq
+			};
+			
+			if(ath_tx_start(sc->hw, skb, &txctl)) {
+				printk(KERN_ERR "Failed to send! Discarding...\n");
+				ieee80211_free_txskb(sc->hw, skb);
+				ath_txq_unlock(sc, txq);
+				return;
+			} else {
+				printk(KERN_ERR "Direct send! Skipping tasklet.\n");
+				ath_txq_unlock(sc, txq);
+				return;
+			}
+		}
+		ath_txq_unlock(sc, txq);
+	}
+
+	// Put 
+	spin_lock_bh(&sc->tx.queue_lock);
+	if (skb_queue_len_lockless(&sc->tx.queue) > 255) {
+		printk(KERN_ERR "CONGESTED: Length of queue exceeded 255! Dropping packet...\n", skb->priority);
+		spin_unlock_bh(&sc->tx.queue_lock);
+		goto exit;
+	}
+	__skb_queue_tail(&sc->tx.queue, skb);
+
+	spin_unlock_bh(&sc->tx.queue_lock);
+
+	tasklet_schedule(&sc->intr_tq);
+
+	// printk(KERN_ERR "ATH MON TX: Pushed packet onto queue (slice) [%u]\n", skb->priority);
+	return;
 
 	if (sc->ps_enabled) {
 		/*
@@ -815,7 +888,7 @@ static void ath9k_tx(struct ieee80211_hw
 	}
 
 	memset(&txctl, 0, sizeof(struct ath_tx_control));
-	txctl.txq = sc->tx.txq_map[skb_get_queue_mapping(skb)];
+	txctl.txq = sc->tx.txq_map[0]; // It doesn't matter - send to the default
 	txctl.sta = control->sta;
 
 	ath_dbg(common, XMIT, "transmitting packet, skb: %p\n", skb);
@@ -1246,11 +1319,11 @@ static void ath9k_assign_hw_queues(struc
 		return;
 
 	for (i = 0; i < IEEE80211_NUM_ACS; i++)
-		vif->hw_queue[i] = i;
+		vif->hw_queue[i] = 0;
 
 	if (vif->type == NL80211_IFTYPE_AP ||
 	    vif->type == NL80211_IFTYPE_MESH_POINT)
-		vif->cab_queue = hw->queues - 2;
+		vif->cab_queue = ATH9K_NUM_TX_QUEUES - 2;
 	else
 		vif->cab_queue = IEEE80211_INVAL_HW_QUEUE;
 }
@@ -1646,37 +1719,57 @@ static int ath9k_conf_tx(struct ieee8021
 {
 	struct ath_softc *sc = hw->priv;
 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
-	struct ath_txq *txq;
-	struct ath9k_tx_queue_info qi;
-	int ret = 0;
+	int i = 0;
 
-	if (queue >= IEEE80211_NUM_ACS)
-		return 0;
+	ath9k_ps_wakeup(sc);
 
-	txq = sc->tx.txq_map[queue];
+	printk(KERN_ERR "Saving slice config [%d], aifs: %d, cw_min: %d, cw_max: %d, txop: %d\n",
+		queue, params->aifs, params->cw_min,
+		params->cw_max, params->txop);
 
-	ath9k_ps_wakeup(sc);
-	mutex_lock(&sc->mutex);
+	spin_lock_bh(&sc->tx.slices[queue].slice_cfg_lock);
+	sc->tx.slices[queue].slice_config.tqi_burstTime = params->txop * 32;
+	sc->tx.slices[queue].slice_config.tqi_cwmin = params->cw_min;
+	sc->tx.slices[queue].slice_config.tqi_cwmax = params->cw_max;
+	sc->tx.slices[queue].slice_config.tqi_aifs = params->aifs;
+	spin_unlock_bh(&sc->tx.slices[queue].slice_cfg_lock);
+
+	for (i = 0; i < ATH_NUM_DATA_TX_QUEUES; i++) {
+		ath_txq_lock(sc, &sc->tx.txq[i]);
+		if (sc->tx.txq[i].current_slice == queue) {
+			ath9k_configure_queue_for_slice(sc, queue, &sc->tx.txq[i]);
+		}
+		ath_txq_unlock(sc, &sc->tx.txq[i]);
+	}
 
-	memset(&qi, 0, sizeof(struct ath9k_tx_queue_info));
 
-	qi.tqi_aifs = params->aifs;
-	qi.tqi_cwmin = params->cw_min;
-	qi.tqi_cwmax = params->cw_max;
-	qi.tqi_burstTime = params->txop * 32;
+	ath9k_ps_restore(sc);
 
-	ath_dbg(common, CONFIG,
-		"Configure tx [queue/halq] [%d/%d], aifs: %d, cw_min: %d, cw_max: %d, txop: %d\n",
-		queue, txq->axq_qnum, params->aifs, params->cw_min,
-		params->cw_max, params->txop);
+	return 0;
+}
 
-	ath_update_max_aggr_framelen(sc, queue, qi.tqi_burstTime);
+// Takes a txq lock
+int ath9k_configure_queue_for_slice(struct ath_softc *sc, u16 slice, struct ath_txq *txq)
+{
+	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
+	struct ath9k_tx_queue_info *params = &sc->tx.slices[slice].slice_config;
+	struct ath9k_tx_queue_info qi;
+	int ret = 0;
+
+	memset(&qi, 0, sizeof(struct ath9k_tx_queue_info));
+
+	spin_lock_bh(&sc->tx.slices[slice].slice_cfg_lock);	
+	qi.tqi_aifs = params->tqi_aifs;
+	qi.tqi_cwmin = params->tqi_cwmin;
+	qi.tqi_cwmax = params->tqi_cwmax;
+	spin_unlock_bh(&sc->tx.slices[slice].slice_cfg_lock);	
+
+	printk(KERN_ERR "Configure tx [slice/queue] [%d/%d], aifs: %d, cw_min: %d, cw_max: %d, txop*32: %d\n",
+		slice, txq->axq_qnum, params->tqi_aifs, params->tqi_cwmin,
+		params->tqi_cwmax, params->tqi_burstTime);
 	ret = ath_txq_update(sc, txq->axq_qnum, &qi);
 	if (ret)
-		ath_err(common, "TXQ Update failed\n");
-
-	mutex_unlock(&sc->mutex);
-	ath9k_ps_restore(sc);
+		printk(KERN_ERR "TXQ Update failed!\n");
 
 	return ret;
 }
@@ -2136,7 +2229,8 @@ void __ath9k_flush(struct ieee80211_hw *
 		spin_lock_bh(&sc->sc_pcu_lock);
 		drain_txq = ath_drain_all_txq(sc);
 		spin_unlock_bh(&sc->sc_pcu_lock);
-
+		
+		printk(KERN_ERR "Flushing queues!");
 		if (!drain_txq)
 			ath_reset(sc, NULL);
 
--- a/drivers/net/wireless/ath/ath9k/xmit.c
+++ b/drivers/net/wireless/ath/ath9k/xmit.c
@@ -119,18 +119,13 @@ void __ath_tx_queue_tid(struct ath_softc
 	struct ath_chanctx *ctx = avp->chanctx;
 	struct ath_acq *acq;
 	struct list_head *tid_list;
-	u8 acno = TID_TO_WME_AC(tid->tidno);
 
 	if (!ctx || !list_empty(&tid->list))
 		return;
 
 
-	acq = &ctx->acq[acno];
-	if ((sc->airtime_flags & AIRTIME_USE_NEW_QUEUES) &&
-	    tid->an->airtime_deficit[acno] > 0)
-		tid_list = &acq->acq_new;
-	else
-		tid_list = &acq->acq_old;
+	acq = &ctx->acq;
+	tid_list = &acq->acq_old;
 
 	list_add_tail(&tid->list, tid_list);
 }
@@ -144,7 +139,7 @@ void ath_tx_queue_tid(struct ath_softc *
 	if (!ctx || !list_empty(&tid->list))
 		return;
 
-	acq = &ctx->acq[TID_TO_WME_AC(tid->tidno)];
+	acq = &ctx->acq;
 	spin_lock_bh(&acq->lock);
 	__ath_tx_queue_tid(sc, tid);
 	spin_unlock_bh(&acq->lock);
@@ -158,6 +153,9 @@ void ath9k_wake_tx_queue(struct ieee8021
 	struct ath_atx_tid *tid = (struct ath_atx_tid *) queue->drv_priv;
 	struct ath_txq *txq = tid->txq;
 
+	printk(KERN_ERR "ATH WAKE Q: Ignore wake notification, expecting push not pull!\n");
+	return;
+
 	ath_dbg(common, QUEUE, "Waking TX queue: %pM (%d)\n",
 		queue->sta ? queue->sta->addr : queue->vif->addr,
 		tid->tidno);
@@ -204,7 +202,7 @@ static void ath_txq_skb_done(struct ath_
 	if (q < 0)
 		return;
 
-	txq = sc->tx.txq_map[q];
+	txq = &sc->tx.txq[q];
 	if (WARN_ON(--txq->pending_frames < 0))
 		txq->pending_frames = 0;
 
@@ -246,11 +244,11 @@ ath_tid_pull(struct ath_atx_tid *tid)
 	}
 
 	q = skb_get_queue_mapping(skb);
-	if (tid->txq == sc->tx.txq_map[q]) {
+	// if (tid->txq == sc->tx.txq_map[q]) {
 		fi = get_frame_info(skb);
 		fi->txq = q;
 		++tid->txq->pending_frames;
-	}
+	// }
 
 	return skb;
 }
@@ -724,7 +722,7 @@ static void ath_tx_count_airtime(struct
 
 	if (sc->airtime_flags & AIRTIME_USE_TX) {
 		int q = txq->mac80211_qnum;
-		struct ath_acq *acq = &sc->cur_chan->acq[q];
+		struct ath_acq *acq = &sc->cur_chan->acq;
 
 		spin_lock_bh(&acq->lock);
 		an->airtime_deficit[q] -= airtime;
@@ -780,8 +778,8 @@ static void ath_tx_process_buffer(struct
 	} else
 		ath_tx_complete_aggr(sc, txq, bf, bf_head, sta, tid, ts, txok);
 
-	if (!flush)
-		ath_txq_schedule(sc, txq);
+	// if (!flush)
+	// 	ath_txq_schedule(sc, txq);
 }
 
 static bool ath_lookup_legacy(struct ath_buf *bf)
@@ -814,7 +812,7 @@ static u32 ath_lookup_rate(struct ath_so
 	struct ieee80211_tx_rate *rates;
 	u32 max_4ms_framelen, frmlen;
 	u16 aggr_limit, bt_aggr_limit, legacy = 0;
-	int q = tid->txq->mac80211_qnum;
+	int q = tid->txq->current_slice;
 	int i;
 
 	skb = bf->bf_mpdu;
@@ -1628,7 +1626,7 @@ void ath_tx_aggr_sleep(struct ieee80211_
 
 	ath_dbg(common, XMIT, "%s called\n", __func__);
 
-	for (tidno = 0; tidno < IEEE80211_NUM_TIDS; tidno++) {
+	for (tidno = 0; tidno < EMPOWER_NUM_SLICE; tidno++) {
 		tid = ath_node_to_tid(an, tidno);
 		txq = tid->txq;
 
@@ -1657,7 +1655,7 @@ void ath_tx_aggr_wakeup(struct ath_softc
 
 	ath_dbg(common, XMIT, "%s called\n", __func__);
 
-	for (tidno = 0; tidno < IEEE80211_NUM_TIDS; tidno++) {
+	for (tidno = 0; tidno < EMPOWER_NUM_SLICE; tidno++) {
 		tid = ath_node_to_tid(an, tidno);
 		txq = tid->txq;
 
@@ -1702,6 +1700,9 @@ void ath9k_release_buffered_frames(struc
 	int sent = 0;
 	int i;
 
+	printk(KERN_ERR "Ignoring release buffered frames\n");
+	return;
+
 	INIT_LIST_HEAD(&bf_q);
 	for (i = 0; tids && nframes; i++, tids >>= 1) {
 		struct ath_atx_tid *tid;
@@ -1760,16 +1761,16 @@ struct ath_txq *ath_txq_setup(struct ath
 {
 	struct ath_hw *ah = sc->sc_ah;
 	struct ath9k_tx_queue_info qi;
-	static const int subtype_txq_to_hwq[] = {
-		[IEEE80211_AC_BE] = ATH_TXQ_AC_BE,
-		[IEEE80211_AC_BK] = ATH_TXQ_AC_BK,
-		[IEEE80211_AC_VI] = ATH_TXQ_AC_VI,
-		[IEEE80211_AC_VO] = ATH_TXQ_AC_VO,
-	};
+	// static const int subtype_txq_to_hwq[] = {
+	// 	[IEEE80211_AC_BE] = ATH_TXQ_AC_BE,
+	// 	[IEEE80211_AC_BK] = ATH_TXQ_AC_BK,
+	// 	[IEEE80211_AC_VI] = ATH_TXQ_AC_VI,
+	// 	[IEEE80211_AC_VO] = ATH_TXQ_AC_VO,
+	// };
 	int axq_qnum, i;
 
 	memset(&qi, 0, sizeof(qi));
-	qi.tqi_subtype = subtype_txq_to_hwq[subtype];
+	qi.tqi_subtype = subtype;
 	qi.tqi_aifs = ATH9K_TXQ_USEDEFAULT;
 	qi.tqi_cwmin = ATH9K_TXQ_USEDEFAULT;
 	qi.tqi_cwmax = ATH9K_TXQ_USEDEFAULT;
@@ -1975,89 +1976,134 @@ void ath_tx_cleanupq(struct ath_softc *s
 	sc->tx.txqsetup &= ~(1<<txq->axq_qnum);
 }
 
-/* For each acq entry, for each tid, try to schedule packets
- * for transmit until ampdu_depth has reached min Q depth.
- */
-void ath_txq_schedule(struct ath_softc *sc, struct ath_txq *txq)
+bool ath_txq_schedule(struct ath_softc *sc, struct ath_txq *txq)
 {
 	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
-	struct ath_atx_tid *tid;
-	struct list_head *tid_list;
-	struct ath_acq *acq;
-	bool active = AIRTIME_ACTIVE(sc->airtime_flags);
-
-	if (txq->mac80211_qnum < 0)
-		return;
+	struct ath_empower_slice *slice;
+	int ret;
+	bool has_frames;
+	struct sk_buff *skb;
+	bool sent_something = false;
 
-	if (test_bit(ATH_OP_HW_RESET, &common->op_flags))
-		return;
+	// printk(KERN_ERR "Scheduling for TXQ [%u], currently serving slice [%u]\n", txq->axq_qnum, txq->current_slice);
+	// Losing the lock here is fine because other threads can only add not consume
 
-	spin_lock_bh(&sc->chan_lock);
-	rcu_read_lock();
-	acq = &sc->cur_chan->acq[txq->mac80211_qnum];
+	spin_lock_bh(&sc->tx.queue_lock);
 
-	if (sc->cur_chan->stopped)
+	if (skb_queue_empty_lockless(&sc->tx.queue)) {
+		spin_unlock_bh(&sc->tx.queue_lock);
 		goto out;
+	}
 
-begin:
-	tid_list = &acq->acq_new;
-	if (list_empty(tid_list)) {
-		tid_list = &acq->acq_old;
-		if (list_empty(tid_list))
-			goto out;
+	skb = __skb_peek(&sc->tx.queue);
+	spin_unlock_bh(&sc->tx.queue_lock);
+
+	slice = &sc->tx.slices[skb->priority];
+	// If the slice is flagged as handled OR we are not a wildcard and someone else is, let them handle it
+	if (slice->slice != txq->current_slice && (((sc->tx.handled_slices & BIT(slice->slice)) != 0) || ((txq->current_slice != -1) && sc->tx.inactive_queues != 0))) {
+		goto out;
 	}
-	tid = list_first_entry(tid_list, struct ath_atx_tid, list);
 
-	if (active && tid->an->airtime_deficit[txq->mac80211_qnum] <= 0) {
-		spin_lock_bh(&acq->lock);
-		tid->an->airtime_deficit[txq->mac80211_qnum] += ATH_AIRTIME_QUANTUM;
-		list_move_tail(&tid->list, &acq->acq_old);
-		spin_unlock_bh(&acq->lock);
-		goto begin;
+	if (txq->axq_depth >= ATH_NON_AGGR_MIN_QDEPTH) {
+		spin_lock_bh(&sc->tx.queue_lock);
+		skb = __skb_dequeue(&sc->tx.queue);
+		spin_unlock_bh(&sc->tx.queue_lock);
+		ieee80211_free_txskb(sc->hw, skb);
+		goto out;
 	}
 
-	if (!ath_tid_has_buffered(tid)) {
-		spin_lock_bh(&acq->lock);
-		if ((tid_list == &acq->acq_new) && !list_empty(&acq->acq_old))
-			list_move_tail(&tid->list, &acq->acq_old);
-		else {
-			list_del_init(&tid->list);
+	// We are holding the txq lock here, protected
+	has_frames = txq->axq_depth > 0;
+	if (txq->current_slice != slice->slice && !has_frames) {
+
+		printk(KERN_ERR  "Queue is currently empty and has different slice, reconfiguring...\n");
+		ret = ath9k_configure_queue_for_slice(sc, slice->slice, txq);
+		if (ret) {
+			printk(KERN_ERR "Error reconfiguring slice!\n");
+ 			goto out;
 		}
-		spin_unlock_bh(&acq->lock);
-		goto begin;
+
+		if (txq->current_slice != -1) {
+			sc->tx.handled_slices &= ~(BIT(txq->current_slice)); // Erase the slice as handled
+		} else {
+			sc->tx.inactive_queues &= ~(BIT(txq->axq_qnum)); // Set the current hw queue as active
+		}
+
+		txq->current_slice = slice->slice;
+
+		sc->tx.handled_slices |= (BIT(txq->current_slice));
+
+		printk(KERN_ERR "Changed queue params, handled_slices: [%u], inactive_queues: [%u]\n", sc->tx.handled_slices, sc->tx.inactive_queues);
+
+	} else if (txq->current_slice != slice->slice && has_frames) {
+		// We can't TX and we also can't change the queue props
+		printk(KERN_ERR "Queue is busy AND misconfigured, skipping\n");
+		goto out;
 	}
 
+	struct ath_tx_control txctl = {
+		.txq = txq
+	};
 
-	/*
-	 * If we succeed in scheduling something, immediately restart to make
-	 * sure we keep the HW busy.
-	 */
-	if(ath_tx_sched_aggr(sc, txq, tid)) {
-		if (!active) {
-			spin_lock_bh(&acq->lock);
-			list_move_tail(&tid->list, &acq->acq_old);
-			spin_unlock_bh(&acq->lock);
+	while (skb->priority == slice->slice) {
+		spin_lock_bh(&sc->tx.queue_lock);
+		skb = __skb_dequeue(&sc->tx.queue);
+		spin_unlock_bh(&sc->tx.queue_lock);
+
+		sent_something = true;
+		if(ath_tx_start(sc->hw, skb, &txctl)) {
+			printk(KERN_ERR "Failed to send! Discarding...\n");
+			ieee80211_free_txskb(sc->hw, skb);
+			break;
+		}
+		// printk(KERN_ERR "Sent packet!\n");
+
+		spin_lock_bh(&sc->tx.queue_lock);
+		if (skb_queue_empty_lockless(&sc->tx.queue)) {
+			spin_unlock_bh(&sc->tx.queue_lock);
+			break;
 		}
-		goto begin;
+
+		skb = __skb_peek(&sc->tx.queue);
+		spin_unlock_bh(&sc->tx.queue_lock);
 	}
 
 out:
-	rcu_read_unlock();
-	spin_unlock_bh(&sc->chan_lock);
+	return sent_something;
 }
 
 void ath_txq_schedule_all(struct ath_softc *sc)
 {
 	struct ath_txq *txq;
 	int i;
-
-	for (i = 0; i < IEEE80211_NUM_ACS; i++) {
-		txq = sc->tx.txq_map[i];
-
-		spin_lock_bh(&txq->axq_lock);
-		ath_txq_schedule(sc, txq);
-		spin_unlock_bh(&txq->axq_lock);
-	}
+	bool ret = false;
+	printk(KERN_ERR "Sched all ignored!");
+	return;
+
+	// for (i = 0; i < ATH_NUM_DATA_TX_QUEUES; i++) {
+	// 	txq = &sc->tx.txq[i];
+
+	// 	if (txq->current_slice == -1) {
+	// 		ath_txq_schedule_emp(sc, txq, true);
+	// 		ret = true;
+	// 	}
+
+	// 	// If we scheduled something, we are done!
+	// 	if (ret) {
+	// 		return;
+	// 	}
+	// }
+
+
+	// for (i = 0; i < ATH_NUM_DATA_TX_QUEUES; i++) {
+	// 	txq = &sc->tx.txq[i];
+	// 	// Try again, but allow changing queue props regardless of anything
+	// 	ret = ath_txq_schedule_emp(sc, txq, true);
+
+	// 	if (ret) {
+	// 		return;
+	// 	}
+	// }
 }
 
 /***********/
@@ -2399,11 +2445,10 @@ int ath_tx_start(struct ieee80211_hw *hw
 		tid = ath_get_skb_tid(sc, an, skb);
 	}
 
-	ath_txq_lock(sc, txq);
-	if (txq == sc->tx.txq_map[q]) {
-		fi->txq = q;
+	// if (txq == sc->tx.txq_map[q]) {
+		// fi->txq = q;
 		++txq->pending_frames;
-	}
+	// }
 
 	bf = ath_tx_setup_buffer(sc, txq, tid, skb);
 	if (!bf) {
@@ -2424,7 +2469,6 @@ int ath_tx_start(struct ieee80211_hw *hw
 	ath_tx_send_normal(sc, txq, tid, skb);
 
 out:
-	ath_txq_unlock(sc, txq);
 
 	return 0;
 }
@@ -2661,7 +2705,6 @@ static void ath_tx_processq(struct ath_s
 	ath_dbg(common, QUEUE, "tx queue %d (%x), link %p\n",
 		txq->axq_qnum, ath9k_hw_gettxbuf(sc->sc_ah, txq->axq_qnum),
 		txq->axq_link);
-
 	ath_txq_lock(sc, txq);
 	for (;;) {
 		if (test_bit(ATH_OP_HW_RESET, &common->op_flags))
@@ -2669,7 +2712,7 @@ static void ath_tx_processq(struct ath_s
 
 		if (list_empty(&txq->axq_q)) {
 			txq->axq_link = NULL;
-			ath_txq_schedule(sc, txq);
+			// ath_txq_schedule(sc, txq);
 			break;
 		}
 		bf = list_first_entry(&txq->axq_q, struct ath_buf, list);
@@ -2887,10 +2930,10 @@ void ath_tx_node_init(struct ath_softc *
 	struct ath_atx_tid *tid;
 	int tidno, acno;
 
-	for (acno = 0; acno < IEEE80211_NUM_ACS; acno++)
+	for (acno = 0; acno < EMPOWER_NUM_SLICE; acno++)
 		an->airtime_deficit[acno] = ATH_AIRTIME_QUANTUM;
 
-	for (tidno = 0; tidno < IEEE80211_NUM_TIDS; tidno++) {
+	for (tidno = 0; tidno < EMPOWER_NUM_SLICE; tidno++) {
 		tid = ath_node_to_tid(an, tidno);
 		tid->an        = an;
 		tid->tidno     = tidno;
@@ -2903,7 +2946,7 @@ void ath_tx_node_init(struct ath_softc *
 		__skb_queue_head_init(&tid->retry_q);
 		INIT_LIST_HEAD(&tid->list);
 		acno = TID_TO_WME_AC(tidno);
-		tid->txq = sc->tx.txq_map[acno];
+		tid->txq = sc->tx.txq_map[0];
 
 		if (!an->sta)
 			break; /* just one multicast ath_atx_tid */
@@ -2915,10 +2958,11 @@ void ath_tx_node_cleanup(struct ath_soft
 	struct ath_atx_tid *tid;
 	struct ath_txq *txq;
 	int tidno;
+	struct ath_common *common = ath9k_hw_common(sc->sc_ah);
 
 	rcu_read_lock();
-
-	for (tidno = 0; tidno < IEEE80211_NUM_TIDS; tidno++) {
+	ath_dbg(common, XMIT, "Draining node on the DEFAULT (!!) queue");
+	for (tidno = 0; tidno < EMPOWER_NUM_SLICE; tidno++) {
 		tid = ath_node_to_tid(an, tidno);
 		txq = tid->txq;
 
--- a/net/mac80211/ieee80211_i.h
+++ b/net/mac80211/ieee80211_i.h
@@ -1133,7 +1133,7 @@ struct ieee80211_local {
 	struct codel_params cparams;
 
 	/* protects active_txqs and txqi->schedule_order */
-	spinlock_t active_txq_lock[IEEE80211_NUM_ACS];
+	spinlock_t active_txq_lock[EMPOWER_NUM_SLICE];
 	struct list_head active_txqs[IEEE80211_NUM_ACS];
 	u16 schedule_round[IEEE80211_NUM_ACS];
 
--- a/net/mac80211/tx.c
+++ b/net/mac80211/tx.c
@@ -1196,7 +1196,7 @@ ieee80211_tx_prepare(struct ieee80211_su
 
 	if (tx->sta && ieee80211_is_data_qos(hdr->frame_control) &&
 	    !ieee80211_is_qos_nullfunc(hdr->frame_control) &&
-	    ieee80211_hw_check(&local->hw, AMPDU_AGGREGATION) &&
+	    ieee80211_hw_check(&local->hw, AMPDU_AGGREGATION) && // This should prevent us from entering here
 	    !ieee80211_hw_check(&local->hw, TX_AMPDU_SETUP_IN_HW)) {
 		struct tid_ampdu_tx *tid_tx;
 
@@ -1842,7 +1842,7 @@ bool ieee80211_tx_prepare_skb(struct iee
 
 	info->band = band;
 	info->control.vif = vif;
-	info->hw_queue = vif->hw_queue[skb_get_queue_mapping(skb)];
+	info->hw_queue = 0; // We don't care
 
 	if (invoke_tx_handlers(&tx))
 		return false;
@@ -2199,6 +2199,9 @@ netdev_tx_t ieee80211_monitor_start_xmit
 	u16 len_rthdr;
 	int hdrlen;
 
+	// printk(KERN_ERR "MONITOR TX FOR PRIO/Q [%u/%u]", skb->priority, skb->queue_mapping);
+	// goto fail;
+
 	/* check for not even having the fixed radiotap header part */
 	if (unlikely(skb->len < sizeof(struct ieee80211_radiotap_header)))
 		goto fail; /* too short to be possibly valid */
@@ -3334,13 +3337,13 @@ static void ieee80211_xmit_fast_finish(s
 	else
 		sta->tx_stats.msdu[tid]++;
 
-	info->hw_queue = sdata->vif.hw_queue[skb_get_queue_mapping(skb)];
+	info->hw_queue = sdata->vif.hw_queue[0];
 
 	/* statistics normally done by ieee80211_tx_h_stats (but that
 	 * has to consider fragmentation, so is more complex)
 	 */
-	sta->tx_stats.bytes[skb_get_queue_mapping(skb)] += skb->len;
-	sta->tx_stats.packets[skb_get_queue_mapping(skb)]++;
+	sta->tx_stats.bytes[0] += skb->len;
+	sta->tx_stats.packets[0]++;
 
 	if (pn_offs) {
 		u64 pn;
@@ -3611,8 +3614,7 @@ begin:
 		tx.sdata = rcu_dereference(local->monitor_sdata);
 		if (tx.sdata) {
 			vif = &tx.sdata->vif;
-			info->hw_queue =
-				vif->hw_queue[skb_get_queue_mapping(skb)];
+			info->hw_queue = 0;
 		} else if (ieee80211_hw_check(&local->hw, QUEUE_CONTROL)) {
 			ieee80211_free_txskb(&local->hw, skb);
 			goto begin;
--- a/net/mac80211/util.c
+++ b/net/mac80211/util.c
@@ -240,7 +240,7 @@ __le16 ieee80211_ctstoself_duration(stru
 }
 EXPORT_SYMBOL(ieee80211_ctstoself_duration);
 
-static void __ieee80211_wake_txqs(struct ieee80211_sub_if_data *sdata, int ac)
+static void __ieee80211_wake_txqs(struct ieee80211_sub_if_data *sdata, int tid)
 {
 	struct ieee80211_local *local = sdata->local;
 	struct ieee80211_vif *vif = &sdata->vif;
@@ -255,7 +255,7 @@ static void __ieee80211_wake_txqs(struct
 	if (sdata->vif.type == NL80211_IFTYPE_AP)
 		ps = &sdata->bss->ps;
 
-	sdata->vif.txqs_stopped[ac] = false;
+	sdata->vif.txqs_stopped[tid] = false;
 
 	list_for_each_entry_rcu(sta, &local->sta_list, list) {
 		if (sdata != sta->sdata)
@@ -266,7 +266,7 @@ static void __ieee80211_wake_txqs(struct
 
 			txqi = to_txq_info(txq);
 
-			if (ac != txq->ac)
+			if (tid != txq->tid)
 				continue;
 
 			if (!test_and_clear_bit(IEEE80211_TXQ_STOP_NETIF_TX,
@@ -285,7 +285,7 @@ static void __ieee80211_wake_txqs(struct
 	txqi = to_txq_info(vif->txq);
 
 	if (!test_and_clear_bit(IEEE80211_TXQ_STOP_NETIF_TX, &txqi->flags) ||
-	    (ps && atomic_read(&ps->num_sta_ps)) || ac != vif->txq->ac)
+	    (ps && atomic_read(&ps->num_sta_ps)) || tid != vif->txq->tid)
 		goto out;
 
 	spin_unlock_bh(&fq->lock);
@@ -300,17 +300,14 @@ void ieee80211_wake_txqs(unsigned long d
 {
 	struct ieee80211_local *local = (struct ieee80211_local *)data;
 	struct ieee80211_sub_if_data *sdata;
-	int n_acs = IEEE80211_NUM_ACS;
+	int n_acs = EMPOWER_NUM_SLICE;
 	unsigned long flags;
 	int i;
 
 	rcu_read_lock();
 	spin_lock_irqsave(&local->queue_stop_reason_lock, flags);
 
-	if (local->hw.queues < IEEE80211_NUM_ACS)
-		n_acs = 1;
-
-	for (i = 0; i < local->hw.queues; i++) {
+	for (i = 0; i < EMPOWER_NUM_SLICE; i++) {
 		if (local->queue_stop_reasons[i])
 			continue;
 
@@ -319,10 +316,10 @@ void ieee80211_wake_txqs(unsigned long d
 			int ac;
 
 			for (ac = 0; ac < n_acs; ac++) {
-				int ac_queue = sdata->vif.hw_queue[ac];
+				// int ac_queue = sdata->vif.hw_queue[ac];
 
-				if (ac_queue == i ||
-				    sdata->vif.cab_queue == i)
+				// if (ac_queue == i ||
+				//     sdata->vif.cab_queue == i)
 					__ieee80211_wake_txqs(sdata, ac);
 			}
 		}
--- a/net/mac80211/wme.c
+++ b/net/mac80211/wme.c
@@ -149,6 +149,9 @@ u16 __ieee80211_select_queue(struct ieee
 	struct mac80211_qos_map *qos_map;
 	bool qos;
 
+	if (skb->priority < EMPOWER_NUM_SLICE)
+		return skb->priority;
+
 	/* all mesh/ocb stations are required to support WME */
 	if (sdata->vif.type == NL80211_IFTYPE_MESH_POINT ||
 	    sdata->vif.type == NL80211_IFTYPE_OCB)
@@ -247,11 +250,10 @@ void ieee80211_set_qos_hdr(struct ieee80
 	struct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);
 	u8 tid;
 
-	if (skb->priority & ~IEEE80211_QOS_CTL_TAG1D_MASK > 0) {
-		tid = 0;
-	} else {
-		tid = skb->priority & IEEE80211_QOS_CTL_TAG1D_MASK;
-	}
+	// Force everything to tid = 0
+	// if ((skb->priority & ~IEEE80211_QOS_CTL_TAG1D_MASK) > 0) {
+	tid = 0;
+	// } 
 
 	u8 flags;
 	u8 *p;
--- a/drivers/net/wireless/ath/ath9k/channel.c
+++ b/drivers/net/wireless/ath/ath9k/channel.c
@@ -75,6 +75,7 @@ static int ath_set_channel(struct ath_so
 	}
 
 	hchan = &sc->sc_ah->channels[pos];
+	printk(KERN_ERR "Setting channel!");
 	r = ath_reset(sc, hchan);
 	if (r)
 		return r;
@@ -127,11 +128,11 @@ void ath_chanctx_init(struct ath_softc *
 		INIT_LIST_HEAD(&ctx->vifs);
 		ctx->txpower = ATH_TXPOWER_MAX;
 		ctx->flush_timeout = HZ / 5; /* 200ms */
-		for (j = 0; j < ARRAY_SIZE(ctx->acq); j++) {
-			INIT_LIST_HEAD(&ctx->acq[j].acq_new);
-			INIT_LIST_HEAD(&ctx->acq[j].acq_old);
-			spin_lock_init(&ctx->acq[j].lock);
-		}
+		// for (j = 0; j < ARRAY_SIZE(ctx->acq); j++) {
+			INIT_LIST_HEAD(&ctx->acq.acq_new);
+			INIT_LIST_HEAD(&ctx->acq.acq_old);
+			spin_lock_init(&ctx->acq.lock);
+		// }
 	}
 }
 
@@ -1357,11 +1358,11 @@ void ath9k_offchannel_init(struct ath_so
 	ctx->txpower = ATH_TXPOWER_MAX;
 	cfg80211_chandef_create(&ctx->chandef, chan, NL80211_CHAN_HT20);
 
-	for (i = 0; i < ARRAY_SIZE(ctx->acq); i++) {
-		INIT_LIST_HEAD(&ctx->acq[i].acq_new);
-		INIT_LIST_HEAD(&ctx->acq[i].acq_old);
-		spin_lock_init(&ctx->acq[i].lock);
-	}
+	// for (i = 0; i < ARRAY_SIZE(ctx->acq); i++) {
+		INIT_LIST_HEAD(&ctx->acq.acq_new);
+		INIT_LIST_HEAD(&ctx->acq.acq_old);
+		spin_lock_init(&ctx->acq.lock);
+	// }
 
 	sc->offchannel.chan.offchannel = true;
 }
--- a/drivers/net/wireless/ath/ath9k/recv.c
+++ b/drivers/net/wireless/ath/ath9k/recv.c
@@ -1033,7 +1033,7 @@ static void ath_rx_count_airtime(struct
 	avp = (struct ath_vif *) an->vif->drv_priv;
 	tidno = skb->priority & IEEE80211_QOS_CTL_TID_MASK;
 	acno = TID_TO_WME_AC(tidno);
-	acq = &avp->chanctx->acq[acno];
+	acq = &avp->chanctx->acq;
 
 	rxs = IEEE80211_SKB_RXCB(skb);
 
--- a/drivers/net/wireless/ath/ath.h
+++ b/drivers/net/wireless/ath/ath.h
@@ -287,18 +287,17 @@ enum ATH_DEBUG {
 #define ATH_DBG_DEFAULT (ATH_DBG_FATAL)
 #define ATH_DBG_MAX_LEN 512
 
-#ifdef CPTCFG_ATH_DEBUG
+// #ifdef CPTCFG_ATH_DEBUG
 
-#define ath_dbg(common, dbg_mask, fmt, ...)				\
-do {									\
-	if ((common)->debug_mask & ATH_DBG_##dbg_mask)			\
-		ath_printk(KERN_DEBUG, common, fmt, ##__VA_ARGS__);	\
-} while (0)
+// #define ath_dbg(common, dbg_mask, fmt, ...)				\
+// do {									\
+// 		ath_printk(KERN_ERR, common, fmt, ##__VA_ARGS__);	\
+// } while (0)
 
-#define ATH_DBG_WARN(foo, arg...) WARN(foo, arg)
-#define ATH_DBG_WARN_ON_ONCE(foo) WARN_ON_ONCE(foo)
+// #define ATH_DBG_WARN(foo, arg...) WARN(foo, arg)
+// #define ATH_DBG_WARN_ON_ONCE(foo) WARN_ON_ONCE(foo)
 
-#else
+// #else
 
 static inline  __attribute__ ((format (printf, 3, 4)))
 void _ath_dbg(struct ath_common *common, enum ATH_DEBUG dbg_mask,
@@ -314,7 +313,7 @@ void _ath_dbg(struct ath_common *common,
 	unlikely(__ret_warn_once);				\
 })
 
-#endif /* CPTCFG_ATH_DEBUG */
+// #endif /* CPTCFG_ATH_DEBUG */
 
 /** Returns string describing opmode, or NULL if unknown mode. */
 const char *ath_opmode_to_string(enum nl80211_iftype opmode);
--- a/net/mac80211/cfg.c
+++ b/net/mac80211/cfg.c
@@ -2116,9 +2116,6 @@ static int ieee80211_set_txq_params(stru
 	if (!local->ops->conf_tx)
 		return -EOPNOTSUPP;
 
-	if (local->hw.queues < IEEE80211_NUM_ACS)
-		return -EOPNOTSUPP;
-
 	memset(&p, 0, sizeof(p));
 	p.aifs = params->aifs;
 	p.cw_max = params->cwmax;
@@ -2131,7 +2128,7 @@ static int ieee80211_set_txq_params(stru
 	 */
 	p.uapsd = false;
 
-	ieee80211_regulatory_limit_wmm_params(sdata, &p, params->ac);
+	// ieee80211_regulatory_limit_wmm_params(sdata, &p, params->ac);
 
 	sdata->tx_conf[params->ac] = p;
 	if (drv_conf_tx(local, sdata, params->ac, &p)) {
@@ -2141,7 +2138,7 @@ static int ieee80211_set_txq_params(stru
 		return -EINVAL;
 	}
 
-	ieee80211_bss_info_change_notify(sdata, BSS_CHANGED_QOS);
+	// ieee80211_bss_info_change_notify(sdata, BSS_CHANGED_QOS);
 
 	return 0;
 }
--- a/net/wireless/nl80211.c
+++ b/net/wireless/nl80211.c
@@ -2304,9 +2304,7 @@ static int parse_txq_params(struct nlatt
 	txq_params->cwmax = nla_get_u16(tb[NL80211_TXQ_ATTR_CWMAX]);
 	txq_params->aifs = nla_get_u8(tb[NL80211_TXQ_ATTR_AIFS]);
 
-	if (ac >= NL80211_NUM_ACS)
-		return -EINVAL;
-	txq_params->ac = array_index_nospec(ac, NL80211_NUM_ACS);
+	txq_params->ac = ac;
 	return 0;
 }
 
@@ -2570,9 +2568,9 @@ static int nl80211_set_wiphy(struct sk_b
 		if (!netdev)
 			return -EINVAL;
 
-		if (netdev->ieee80211_ptr->iftype != NL80211_IFTYPE_AP &&
-		    netdev->ieee80211_ptr->iftype != NL80211_IFTYPE_P2P_GO)
-			return -EINVAL;
+		// if (netdev->ieee80211_ptr->iftype != NL80211_IFTYPE_AP &&
+		//     netdev->ieee80211_ptr->iftype != NL80211_IFTYPE_P2P_GO)
+		// 	return -EINVAL;
 
 		if (!netif_running(netdev))
 			return -ENETDOWN;
--- a/net/mac80211/driver-ops.c
+++ b/net/mac80211/driver-ops.c
@@ -166,9 +166,6 @@ int drv_conf_tx(struct ieee80211_local *
 
 	might_sleep();
 
-	if (!check_sdata_in_driver(sdata))
-		return -EIO;
-
 	if (params->cw_min == 0 || params->cw_min > params->cw_max) {
 		/*
 		 * If we can't configure hardware anyway, don't warn. We may
